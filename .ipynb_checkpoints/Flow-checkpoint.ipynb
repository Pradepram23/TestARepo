{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c92e1cb-3503-4566-8595-97488ef03400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conversight import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ad26ecf-792f-4162-a5cc-ff9617771b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conversight import Dataset, TaskLibrary, task , FlowLibrary , Flow, Parameter, SmartAnalytics,   ProactiveInsights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed8ee29-0066-4210-aa18-146d7b76d78c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc045261-8340-476d-9fae-22d299943f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conversight import Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a4904cd-fd27-466d-9524-6dba58bab3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[2023-12-27 08:51:34,686] [INFO] Currently no cluster is running. Please use the start() method to start a cluster\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cs = Cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a61ebd3-b575-4d4e-b10c-cdaadc992172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[2023-12-27 08:51:34,847] [INFO] New cluster initiated, use reload() function to avail this cluster..\u001b[0m\n",
      "\u001b[0;34m[2023-12-27 08:51:34,848] [INFO] If it is not available immediately, please check back later\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cs.newNFS.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511766f4-30be-402e-bd72-b10eaa9ef0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flows loaded !!\n"
     ]
    }
   ],
   "source": [
    "flw = FlowLibrary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfbb82e2-3027-4bcc-b8fa-602a627fe8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks loaded  !!\n"
     ]
    }
   ],
   "source": [
    "tsk = TaskLibrary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd561f1e-c280-4669-b984-d29582b88c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[2023-11-30 06:29:53,654] [INFO] Loading dataset Test_Sanity_v15...\u001b[0m\n",
      "\u001b[0;32m[2023-11-30 06:29:53,812] [DEBUG] Connecting to database STGIT_prod...\u001b[0m\n",
      "\u001b[0;32m[2023-11-30 06:29:54,107] [DEBUG] STGIT_prod connected successfully !!\u001b[0m\n",
      "\u001b[0;34m[2023-11-30 06:29:54,340] [INFO] ***** 6526f3c4-M3P8_bGSi Dataset object created.*****\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset(\"6526f3c4-M3P8_bGSi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "456aec7d-e6b2-4bc8-94fa-aefb77029490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32m[2023-11-30 06:29:57,505] [DEBUG] Connecting to database STGIT_prod...\u001b[0m\n",
      "\u001b[0;32m[2023-11-30 06:29:57,790] [DEBUG] STGIT_prod connected successfully !!\u001b[0m\n",
      "\u001b[0;32m[2023-11-30 06:29:57,816] [DEBUG] Query resolved successfully !!\u001b[0m\n",
      "\u001b[0;32m[2023-11-30 06:29:57,817] [DEBUG] Start Time ====> 2023-11-30 06:29:57.817509 seconds. \u001b[0m\n",
      "\u001b[0;32m[2023-11-30 06:29:58,195] [DEBUG] Time taken to querying ====> 0.377213 seconds. \u001b[0m\n",
      "\u001b[0;34m[2023-11-30 06:29:58,195] [INFO] Response data type from omnisci ====> <class pandas.core.frame.DataFrame>\u001b[0m\n"
     ]
    }
   ],
   "source": [
    " df= ds.sqlDf(\"\"\"Select\n",
    "  @RetailSales.buyer as customer,\n",
    "  @RetailSales.order_date as buyed_id,\n",
    "  @RetailSales.os as Store_unit,\n",
    "  @RetailSales.units as stock\n",
    "from\n",
    "  #RetailSales\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a3677b4-79be-4a4a-8716-f45cab1b0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conversight import Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81afc55c-373b-48fd-98d6-c3a3b04d71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def resolveQuery( dataSetID : str , query: str  , ctx : Context) -> dict:\n",
    "    ''''Task to rsolve the query '''\n",
    "  \n",
    "    try:\n",
    "        import os\n",
    "        import time \n",
    "        import requests \n",
    "        import sys \n",
    "        from csSDK import Dataset\n",
    "        ctx.log.critical(\"CsSSdk are imported  \")\n",
    "        ctx.log.info(\"os , time , requests imported  \")\n",
    "        from conversight import Dataset\n",
    "        ctx.log.info(\"Dataset is impotted  \")\n",
    "        dataEngineURL = \"{}/formatQuery\".format(os.getenv(\"DATAENGINE_SERVICE\"))\n",
    "        ctx.log.info(\"Info lof!!! Data Engine is Connnected  New updated version 3.9version with try and catch  \")\n",
    "        body = {\"query\": query, \"dataSetID\": dataSetID}   \n",
    "        ctx.log.error(\"This is not a error Message Just Ignore ---> Dataset is connected \") \n",
    "        response = requests.post(url=dataEngineURL, json=body)\n",
    "        status = {401:\"Un Authorized\", 500: \"User does not have dataset Access\", 400: \"Bad Request\"}                                                             \n",
    "        if response.status_code in status:\n",
    "            print(\"Error From Data engine {}\".format(status[response.status_code]))\n",
    "            ctx.log.critical(\"Error from Data Engine \")\n",
    "            return {\"error\":status[response.status_code]}\n",
    "        res = response.json()\n",
    "        if res is not None:\n",
    "            print(\"Resolved Query ====> {} \".format(res[\"query\"]))\n",
    "            ctx.log.info(\"Query is Resolved \")\n",
    "            return res \n",
    "        else:\n",
    "            print(\"Error From Resolved Query ====> {} \".format(\"Error from data engine\"))\n",
    "            return {\"error\": \"Empty response from data engine \"}\n",
    "    except Exception as e:\n",
    "        print(\"Error From Resolved Query ====> {} \".format(str(e))) \n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28b18956-4bd3-4ba2-8009-c5c8e40aa29d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tsk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtsk\u001b[49m\u001b[38;5;241m.\u001b[39mSanityTaskdl\u001b[38;5;241m.\u001b[39mresolveQuery\u001b[38;5;241m.\u001b[39mpromote(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tsk' is not defined"
     ]
    }
   ],
   "source": [
    "tsk.SanityTaskdl.resolveQuery.promote(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdd84025-9081-484a-812a-a0b3f83cdd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[2023-12-28 06:38:18,997] [INFO] resolveQuery has been successfully registered. The most recent version available is 4.7 !!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "resolveQuery.register(\"SanityTaskdl\",\"test new tasks\",\"edit\",True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b6c03a1-cd62-4230-9ec7-7e7b7253b27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks loaded  !!\n"
     ]
    }
   ],
   "source": [
    "tsk.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "560d30f9-4cdf-43ab-b8e7-402151ff2c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resolveQuery version switched to 3.9'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsk.SanityTaskdl.resolveQuery.setVersion(3.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74c7ee49-df70-46fd-a68a-190b3d12e161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03a4cba1-4598-4bc1-ac5b-273c9d37052c:4.7'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsk.SanityTaskdl.resolveQuery.Extras.uniqueId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d15a6494-f9d6-45a6-bce4-44f795a1a1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"At this moment U have the following versions: ['0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '1.0', '1.1', '1.2', '1.3', '1.4', '1.5', '1.6', '1.7', '1.8', '2.0', '2.1', '2.2', '2.3', '2.4', '2.5', '2.6', '2.7', '2.8', '2.9', '3.0', '3.1', '3.2', '3.3', '3.4', '3.5', '3.6', '3.7', '3.8', '3.9', '4.0', '4.1', '4.2', '4.3', '4.4', '4.5', '4.6', '4.7']\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsk.SanityTaskdl.resolveQuery.getVersions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3071c80e-8eea-4293-88c0-a41b7912f608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 4.7 for the task resolveQuery has been successfully promoted to P  !!\n",
      "Tasks loaded  !!\n"
     ]
    }
   ],
   "source": [
    "tsk.SanityTaskdl.resolveQuery.promote(\"P\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca543296-dac4-4e7d-98ab-1632e0dda122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31;1m[2023-12-28 06:39:31,706] [CRITICAL] CsSSdk are imported  \u001b[0m\n",
      "\u001b[0;34m[2023-12-28 06:39:31,706] [INFO] os , time , requests imported  \u001b[0m\n",
      "\u001b[0;34m[2023-12-28 06:39:31,707] [INFO] Dataset is impotted  \u001b[0m\n",
      "\u001b[0;34m[2023-12-28 06:39:31,707] [INFO] Info lof!!! Data Engine is Connnected  New updated version 3.9version with try and catch  \u001b[0m\n",
      "\u001b[31;1m[2023-12-28 06:39:31,709] [ERROR] This is not a error Message Just Ignore ---> Dataset is connected \u001b[0m\n",
      "Resolved Query ====> Select\n",
      "  m_645b6cf7_RetailSales.\"m_buyer\" as customer,\n",
      "  m_645b6cf7_RetailSales.\"m_order\" as buyed_id,\n",
      "  m_645b6cf7_RetailSales.\"m_store\" as Store_unit,\n",
      "  m_645b6cf7_RetailSales.\"m_units\" as stock\n",
      "from\n",
      "  m_645b6cf7_RetailSales \n",
      "\u001b[0;34m[2023-12-28 06:39:31,730] [INFO] Query is Resolved \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Select\\n  m_645b6cf7_RetailSales.\"m_buyer\" as customer,\\n  m_645b6cf7_RetailSales.\"m_order\" as buyed_id,\\n  m_645b6cf7_RetailSales.\"m_store\" as Store_unit,\\n  m_645b6cf7_RetailSales.\"m_units\" as stock\\nfrom\\n  m_645b6cf7_RetailSales',\n",
       " 'datasetID': '6448b9f4-CYkYQgs4m',\n",
       " 'period': '',\n",
       " 'startDate': '0001-01-01T00:00:00Z',\n",
       " 'endDate': '0001-01-01T00:00:00Z',\n",
       " 'column_metadata': None,\n",
       " 'additional_data': None,\n",
       " 'connectionDetails': {'connectionID': '296447303',\n",
       "  'connectionType': 'omnisci',\n",
       "  'connectionData': {'url': 'datastore-cpu-6-4.con-db.svc.cluster.local:6274',\n",
       "   'internal_url': '',\n",
       "   'database': 'STGIT_prod',\n",
       "   'schema': 'm_645b6cf7',\n",
       "   'username': 'admin',\n",
       "   'password': 'HyperInteractive',\n",
       "   'dialect': 'omnisci',\n",
       "   'connectorID': '296447303',\n",
       "   'account_id': '',\n",
       "   'tables': ['RetailSales', 'Smart_sales', 'period_Format']}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsk.SanityTaskdl.resolveQuery.run(\"6448b9f4-CYkYQgs4m\",\"\"\"Select\n",
    "  @RetailSales.buyer as customer,\n",
    "  @RetailSales.order as buyed_id,\n",
    "  @RetailSales.store as Store_unit,\n",
    "  @RetailSales.units as stock\n",
    "from\n",
    "  #RetailSales\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aff5042-52e2-4339-8b4a-ab8fd57a272a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version 9.3 has been deleted.\n",
      "Tasks loaded  !!\n"
     ]
    }
   ],
   "source": [
    "tsk.SanityTask.resolveQuery.deleteVersion(9.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7f8e166-32b7-4642-963d-ac7824b7c68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31;1m[2023-12-08 09:32:54,489] [CRITICAL] Packegaes are imported  \u001b[0m\n",
      "\u001b[0;34m[2023-12-08 09:32:54,490] [INFO] os , time , requests imported  \u001b[0m\n",
      "\u001b[0;34m[2023-12-08 09:32:54,491] [INFO] Dataset is impotted  \u001b[0m\n",
      "\u001b[0;34m[2023-12-08 09:32:54,491] [INFO] Info lof!!! Data Engine is Connnected  New updated version 2.1 version with try and catch  \u001b[0m\n",
      "\u001b[31;1m[2023-12-08 09:32:54,492] [ERROR] This is not a error Message Just Ignore ---> Dataset is connected \u001b[0m\n",
      "Resolved Query ====> Select\n",
      "  m_645b6cf7_RetailSales.\"m_buyer\" as customer,\n",
      "  m_645b6cf7_RetailSales.\"m_order\" as buyed_id,\n",
      "  m_645b6cf7_RetailSales.\"m_store\" as Store_unit,\n",
      "  m_645b6cf7_RetailSales.\"m_units\" as stock\n",
      "from\n",
      "  m_645b6cf7_RetailSales \n",
      "\u001b[0;34m[2023-12-08 09:32:54,522] [INFO] Query is Resolved \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Select\\n  m_645b6cf7_RetailSales.\"m_buyer\" as customer,\\n  m_645b6cf7_RetailSales.\"m_order\" as buyed_id,\\n  m_645b6cf7_RetailSales.\"m_store\" as Store_unit,\\n  m_645b6cf7_RetailSales.\"m_units\" as stock\\nfrom\\n  m_645b6cf7_RetailSales',\n",
       " 'datasetID': '6448b9f4-CYkYQgs4m',\n",
       " 'period': '',\n",
       " 'startDate': '0001-01-01T00:00:00Z',\n",
       " 'endDate': '0001-01-01T00:00:00Z',\n",
       " 'column_metadata': None,\n",
       " 'additional_data': None,\n",
       " 'connectionDetails': {'connectionID': '296447303',\n",
       "  'connectionType': 'omnisci',\n",
       "  'connectionData': {'url': 'datastore-cpu-6-4.con-db.svc.cluster.local:6274',\n",
       "   'internal_url': '',\n",
       "   'database': 'STGIT_prod',\n",
       "   'schema': 'm_645b6cf7',\n",
       "   'username': 'admin',\n",
       "   'password': 'HyperInteractive',\n",
       "   'dialect': 'omnisci',\n",
       "   'connectorID': '296447303',\n",
       "   'account_id': '',\n",
       "   'tables': ['RetailSales', 'Smart_sales', 'period_Format']}}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resolveQuery.run(\"6448b9f4-CYkYQgs4m\",\"\"\"Select\n",
    "  @RetailSales.buyer as customer,\n",
    "  @RetailSales.order as buyed_id,\n",
    "  @RetailSales.store as Store_unit,\n",
    "  @RetailSales.units as stock\n",
    "from\n",
    "  #RetailSales\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7097eec6-83eb-407c-acde-df6404227016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31;1m[2023-12-28 06:41:09,308] [CRITICAL] CsSSdk are imported  \u001b[0m\n",
      "\u001b[0;34m[2023-12-28 06:41:09,309] [INFO] os , time , requests imported  \u001b[0m\n",
      "\u001b[0;34m[2023-12-28 06:41:09,309] [INFO] Dataset is impotted  \u001b[0m\n",
      "\u001b[0;34m[2023-12-28 06:41:09,310] [INFO] Info lof!!! Data Engine is Connnected  New updated version 3.9version with try and catch  \u001b[0m\n",
      "\u001b[31;1m[2023-12-28 06:41:09,310] [ERROR] This is not a error Message Just Ignore ---> Dataset is connected \u001b[0m\n",
      "Resolved Query ====> Select\n",
      "  m_645b6cf7_RetailSales.\"m_buyer\" as customer,\n",
      "  m_645b6cf7_RetailSales.\"m_order\" as buyed_id,\n",
      "  m_645b6cf7_RetailSales.\"m_store\" as Store_unit,\n",
      "  m_645b6cf7_RetailSales.\"m_units\" as stock\n",
      "from\n",
      "  m_645b6cf7_RetailSales \n",
      "\u001b[0;34m[2023-12-28 06:41:09,339] [INFO] Query is Resolved \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Select\\n  m_645b6cf7_RetailSales.\"m_buyer\" as customer,\\n  m_645b6cf7_RetailSales.\"m_order\" as buyed_id,\\n  m_645b6cf7_RetailSales.\"m_store\" as Store_unit,\\n  m_645b6cf7_RetailSales.\"m_units\" as stock\\nfrom\\n  m_645b6cf7_RetailSales',\n",
       " 'datasetID': '6448b9f4-CYkYQgs4m',\n",
       " 'period': '',\n",
       " 'startDate': '0001-01-01T00:00:00Z',\n",
       " 'endDate': '0001-01-01T00:00:00Z',\n",
       " 'column_metadata': None,\n",
       " 'additional_data': None,\n",
       " 'connectionDetails': {'connectionID': '296447303',\n",
       "  'connectionType': 'omnisci',\n",
       "  'connectionData': {'url': 'datastore-cpu-6-4.con-db.svc.cluster.local:6274',\n",
       "   'internal_url': '',\n",
       "   'database': 'STGIT_prod',\n",
       "   'schema': 'm_645b6cf7',\n",
       "   'username': 'admin',\n",
       "   'password': 'HyperInteractive',\n",
       "   'dialect': 'omnisci',\n",
       "   'connectorID': '296447303',\n",
       "   'account_id': '',\n",
       "   'tables': ['RetailSales', 'Smart_sales', 'period_Format']}}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsk.SanityTaskdl.resolveQuery.run(\"6448b9f4-CYkYQgs4m\", \"\"\"Select\n",
    "  @RetailSales.buyer as customer,\n",
    "  @RetailSales.order as buyed_id,\n",
    "  @RetailSales.store as Store_unit,\n",
    "  @RetailSales.units as stock\n",
    "from\n",
    "  #RetailSales\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0773684a-6434-4e8b-bd32-f809f9e8bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@task\n",
    "def omnisciToPandas(queryInfo: dict) -> pandas.core.frame.DataFrame:\n",
    "    '''test doc''' \n",
    "    \n",
    "    try:\n",
    "        from conversight import TaskRunError , Context\n",
    "        import pyarrow as pa\n",
    "        #from conversight import Context\n",
    "        ctx = Context()\n",
    "        from heavyai import connect \n",
    "        if isinstance(queryInfo, TaskRunError):\n",
    "            ctx.log.error(\"Received error from previous task, skipping the process: {}\".format(queryInfo))\n",
    "            return queryInfo\n",
    "    \n",
    "        fullUrl = queryInfo[\"connectionDetails\"][\"connectionData\"][\"url\"].split(\":\")\n",
    "        ctx.log.info(\" Version is 2.1  \")\n",
    "        ctx.log.critical(\"\"\"Expand and Collapse Rows in pivot tables is a powerful feature that allows users to control the level of detail displayed in their data analysis. By expanding or collapsing rows, analysts can effectively manage large datasets and gain better visibility into the underlying information. The expand and collapse functionality in pivot tables provides valuable control over data visibility, enabling analysts to focus on specific details or obtain a high-level overview of their data.\"\"\")\n",
    "        con = connect(\n",
    "            host=fullUrl[0],\n",
    "           \n",
    "            dbname=queryInfo[\"connectionDetails\"][\"connectionData\"][\"database\"],\n",
    "            user=queryInfo[\"connectionDetails\"][\"connectionData\"][\"username\"],\n",
    "          \n",
    "            port=int(fullUrl[1]),\n",
    "            password=queryInfo[\"connectionDetails\"][\"connectionData\"][\"password\"],\n",
    "        )\n",
    "        df = con.select_ipc(queryInfo[\"query\"])\n",
    "        ctx.log.warning(\"df is --------------------------->\",df)\n",
    "       \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"Exception in omnisciToPandas: {}\".format(str(e)))\n",
    "        return {\"status\": \"failed\", \"message\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b82f79c-a0bc-4af3-81b5-a37835a76a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[2023-12-08 09:34:15,345] [INFO]  Version is 2.1  \u001b[0m\n",
      "\u001b[31;1m[2023-12-08 09:34:15,346] [CRITICAL] Expand and Collapse Rows in pivot tables is a powerful feature that allows users to control the level of detail displayed in their data analysis. By expanding or collapsing rows, analysts can effectively manage large datasets and gain better visibility into the underlying information. The expand and collapse functionality in pivot tables provides valuable control over data visibility, enabling analysts to focus on specific details or obtain a high-level overview of their data.\u001b[0m\n",
      "Exception in omnisciToPandas: SQL Error: From line 2, column 6 to line 2, column 29: Object 'm_645b6cf7_RetailSales' not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'failed',\n",
       " 'message': \"SQL Error: From line 2, column 6 to line 2, column 29: Object 'm_645b6cf7_RetailSales' not found\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omnisciToPandas.run({'query': 'Select\\n  m_645b6cf7_RetailSales.\"m_buyer\" as customer,\\n  m_645b6cf7_RetailSales.\"m_order\" as buyed_id,\\n  m_645b6cf7_RetailSales.\"m_store\" as Store_unit,\\n  m_645b6cf7_RetailSales.\"m_units\" as stock\\nfrom\\n  m_645b6cf7_RetailSales',\n",
    " 'datasetID': '6448b9f4-CYkYQgs4m',\n",
    " 'period': '',\n",
    " 'startDate': '0001-01-01T00:00:00Z',\n",
    " 'endDate': '0001-01-01T00:00:00Z',\n",
    " 'column_metadata': None,\n",
    " 'additional_data': None,\n",
    " 'connectionDetails': {'connectionID': '296447303',\n",
    "  'connectionType': 'omnisci',\n",
    "  'connectionData': {'url': 'datastore-cpu-6-4.con-db.svc.cluster.local:6274',\n",
    "   'internal_url': '',\n",
    "   'database': 'STGIT_prod',\n",
    "   'schema': 'm_645b6cf7',\n",
    "   'username': 'admin',\n",
    "   'password': 'HyperInteractive',\n",
    "   'dialect': 'omnisci',\n",
    "   'connectorID': '296447303',\n",
    "   'account_id': '',\n",
    "   'tables': ['RetailSales', 'Smart_sales', 'period_Format']}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3e13d12-58be-4bb5-b9bf-256befa82ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[2023-12-08 09:34:37,583] [INFO] omnisciToPandas has been successfully registered. The most recent version available is 3.3 !!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "omnisciToPandas.register(\"SanityTask\",\"test new tasks\",\"edit\",True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42c0a767-f632-4ba5-b21b-43d0ae01f15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks loaded  !!\n"
     ]
    }
   ],
   "source": [
    "tsk.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "636176a6-a26b-40a4-88ba-1b4de71b5058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conversight import Context  , SmartAnalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6fd51e-d6c9-49d1-bc33-dd1bb1d93d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = Context ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbdb5f6d-79e6-4ad0-965e-b9e63374632b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;32m[2023-06-19 07:48:01,107] [DEBUG] Getting connector info....\u001b[0m\n",
      "\u001b[0;32m[2023-06-19 07:48:01,152] [DEBUG] Connecting to database STGIT_prod...\u001b[0m\n",
      "\u001b[0;32m[2023-06-19 07:48:01,407] [DEBUG] STGIT_prod connected successfully !!\u001b[0m\n",
      "\u001b[0;34m[2023-06-19 07:48:01,710] [INFO] smart analytics loaded successfully for the dataset ====> [6448b9f4-CYkYQgs4m]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sm = SmartAnalytics(\"6448b9f4-CYkYQgs4m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee402e-c206-481c-be09-5b1869d1b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6958fc01-c39a-4f23-813d-a28e6ac510cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def createSmartAnalytics(ctx:Context,\n",
    "    objectName: str, dataSetId: str, dataFrame: pandas.core.frame.DataFrame , isArrow:bool=False , isOverwrite :bool = True)-> dict :\n",
    "    '''Task will cretae smart Analytics '''\n",
    "    import time\n",
    "    from conversight import    TaskRunError\n",
    "    import os \n",
    "\n",
    "    try:\n",
    "        print(\"try is executing \")\n",
    "       # ctx =  Context()\n",
    "        \n",
    "        ctx.log.info(\"SA DF OP: {}\".format(dataFrame))\n",
    "                #time.sleep(50)\n",
    "        ctxtoken= ctx.session.token\n",
    "        #print(os.environ)\n",
    "        #ctx.log.info(os.environ)\n",
    "        ctx.log.info(\"log token is by New Version token  ----.\",ctxtoken)\n",
    "        ctx.log.debug(\"Preprocessing log message is !@#$%^&*()_+Q\")\n",
    "       \n",
    "        if isinstance(dataFrame, TaskRunError):\n",
    "            ctx.log.error(\"Error from previous task for dataFrame: {}\".format(dataFrame))\n",
    "            return dataFrame\n",
    "        smObj = SmartAnalytics(dataSetId,ctxtoken)\n",
    "    \n",
    "\n",
    "        isCreated = smObj.create( objectName,  dataFrame,   isArrow, isOverwrite , True , ctxtoken )\n",
    "        if \"status\" in isCreated and isCreated[\"status\"] == \"success\":\n",
    "            return {\"status\": \"success\", \"message \": isCreated[\"message\"]}\n",
    "        elif \"status\" in isCreated and isCreated[\"status\"] != \"success\":\n",
    "            ctx.log.debug(\"Failure msg from  Failed status  \")\n",
    "           \n",
    "            return  {\"status\": \"failed\", \"message\": isCreated[\"message\"]}\n",
    "\n",
    "        else:\n",
    "            print(\n",
    "                \"Status key not found from smart analytics, Error   !!   while creating smart analytics\"\n",
    "            )\n",
    "            return {\"status\": \"failed\", \"message\": isCreated}\n",
    "        ctx.log.critical(\"Smart Analytics   creation is failed \")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error From createSmartAnalytics {}\".format(str(e)))\n",
    "        return {\"status\": \"failed\", \"message\": str(e)}\n",
    "        #return TaskRunError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce668b10-b605-4b3f-b002-06289814d45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"testing without publish\"\n",
    "with Flow(name=\"Product_Flow\", description=description) as flow:\n",
    "    datasetIdEffectiveness = Parameter(\"datasetId\", \"65843ee5-pGLazvOIm\")\n",
    "    Query = Parameter(\"Query\", \"\"\"Select\n",
    "  @RetailSales.store_type as store,\n",
    "  @RetailSales.category as cat,\n",
    "  @RetailSales.item_type as item\n",
    "from\n",
    "  #RetailSales\"\"\")\n",
    "    objectName = Parameter(\"objectName\", \"Flow_Sales\")\n",
    "    isArrow = Parameter(\"arrowData\",False)\n",
    "    isOverWrite = Parameter(\"overwriteTable\",False)\n",
    "    isPublish = Parameter(\"publishDataset\",True)\n",
    "    resolvedForecastQuery = tsk.SanityTaskdl.resolveQuery(datasetIdEffectiveness, Query)\n",
    "    forecast = tsk.SanityTask.omnisciToPandas(resolvedForecastQuery)\n",
    "    smartAnalytics = tsk.SanityTask.createSmartAnalytics(\n",
    "        objectName, datasetIdEffectiveness, forecast, isArrow, isOverWrite)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c08f0650-b885-4de3-852e-ebc6a69516cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[2023-12-28 06:42:46,417] [INFO] [Main-Flow]  Received request from AI Workbench, considering as test run..\u001b[0m\n",
      "\u001b[0;34m[2023-12-28 06:42:46,418] [INFO] [Main-Flow]  No input parameters detected, running with default or previous run parameters\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 06:42:50,882\tWARNING services.py:2002 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=2.23gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[2023-12-28 06:42:54,053] [INFO] Context Actor [98b25e690a33474182e0fae550616c43] deployed..\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2100)\u001b[0m \u001b[31;1m[2023-12-28 06:43:02,716] [CRITICAL] CsSSdk are imported  \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2100)\u001b[0m \u001b[0;34m[2023-12-28 06:43:02,716] [INFO] os , time , requests imported  \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2100)\u001b[0m \u001b[0;34m[2023-12-28 06:43:02,716] [INFO] Dataset is impotted  \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2100)\u001b[0m \u001b[0;34m[2023-12-28 06:43:02,716] [INFO] Info lof!!! Data Engine is Connnected  New updated version 3.9version with try and catch  \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2100)\u001b[0m \u001b[31;1m[2023-12-28 06:43:02,716] [ERROR] This is not a error Message Just Ignore ---> Dataset is connected \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2100)\u001b[0m Resolved Query ====> Select\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2100)\u001b[0m   m_65843f6f_RetailSales.\"m_store_type\" as store,\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2100)\u001b[0m   m_65843f6f_RetailSales.\"m_category\" as cat,\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2100)\u001b[0m   m_65843f6f_RetailSales.\"m_item_type\" as item\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2100)\u001b[0m from\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2100)\u001b[0m   m_65843f6f_RetailSales \n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2100)\u001b[0m \u001b[0;34m[2023-12-28 06:43:02,741] [INFO] Query is Resolved \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2208)\u001b[0m \u001b[0;34m[2023-12-28 06:43:08,600] [INFO]  Version is 2.6  \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m try is executing \n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;34m[2023-12-28 06:43:09,135] [INFO] SA DF OP:              store       cat         item\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m 0      Electronics    Mobile       Tablet\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m 1      Electronics    Mobile  Smart Phone\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m 2      Electronics  Computer      Desktop\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m 3        Discounts    Mobile       Tablet\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m 4        Discounts    Mobile       Tablet\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m ...            ...       ...          ...\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m 15797     Computer    Mobile  Smart Phone\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m 15798    Discounts    Mobile       Tablet\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m 15799  Electronics  Computer       Laptop\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m 15800     Computer  Computer      Desktop\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m 15801     Computer    Mobile  Smart Phone\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m [15802 rows x 3 columns]\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;34m[2023-12-28 06:43:09,135] [INFO] JWT eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJfZG9jIjp7InVzZXJJZCI6ImM2ZWYyMjJmLWRiZDgtNDBlNy05N2ZiLTQ0NDk3NDBhOTRiZSIsImF0aGVuYUlkIjoiMjZiN2JlNzktOGJlMy00ZjUxLThhNGItNTE3YWFjOGQyNDJlIiwib3JnSWQiOiJjNDY2OTJjNS1lYzVmLTRhOWQtOGQ0ZC1jOTNhZmIyNGRjODYiLCJkZXZpY2VJZCI6IjEyMzQ1NiIsImRldmljZU5hbWUiOiJCcm93c2VyV2ViIiwiaXNUcmlhbFVzZXIiOmZhbHNlLCJpc0ZpcnN0VGltZUxvZ2luIjpmYWxzZSwib3JpZ2luIjoibm90ZWJvb2siLCJjcmVhdGVkQXQiOjE3MDM3NDA3NDAxODR9LCJpYXQiOjE3MDM3Mzg3NTZ9.HJwj4_jpSNSfcZxLud4qR9f1xUFKOX7budX149zgW_o\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:09,250] [DEBUG] Getting connector info....\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:09,331] [DEBUG] Connecting to database STGIT_prod...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:09,619] [DEBUG] STGIT_prod connected successfully !!\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:09,620] [DEBUG] Normalised columns [{store: m_store, cat: m_cat, item: m_item}]\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;34m[2023-12-28 06:43:09,621] [INFO] Setting connection details\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:09,621] [DEBUG] Getting connector info....\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:09,679] [DEBUG] Connecting to database STGIT_prod...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:09,964] [DEBUG] STGIT_prod connected successfully !!\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:09,964] [DEBUG] Checking dataset status is active or not...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:10,011] [DEBUG] Dataset is Active...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:10,011] [DEBUG] Does table already exist?\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:11,016] [DEBUG] Creating table m_65843f6f_Flow_Sales...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:11,044] [DEBUG] Table m_65843f6f_Flow_Sales created successfully !!\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:11,044] [DEBUG] Loading table m_65843f6f_Flow_Sales with data...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:11,044] [DEBUG] Load as Arrow format set to ====> [False] and original dataFrame type is ====>  [<class pandas.core.frame.DataFrame>] \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:11,044] [DEBUG] Loading Pandas Dataframe...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:11,335] [DEBUG] Data loaded successfully !!\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:11,336] [DEBUG] Creating metadata for the table [Flow_Sales] ...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:11,336] [DEBUG] Checking dataset status is active or not...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:11,385] [DEBUG] Dataset is Active...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:19,307] [DEBUG] The columns has been created successfully\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[0;32m[2023-12-28 06:43:19,308] [DEBUG] Metadata created successfully !!\u001b[0m\n",
      "\u001b[0;34m[2023-12-28 06:43:19,359] [INFO] [Main-Flow]  Flow response: [{status: success, message : Smart analytics created successfully !!}]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'status': 'success', 'message ': 'Smart analytics created successfully !!'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[33;20m[2023-12-28 06:43:19,358] [WARNING] Dataset [65843ee5-pGLazvOIm] is in following state => status: Active and refreshStatus: Active.Cannot do sme publish.\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m \u001b[31;1m[2023-12-28 06:43:19,358] [ERROR] Dataset [65843ee5-pGLazvOIm] is in following state => status: Active and refreshStatus: Active.Cannot do sme publish.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "flow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ca9f979-2bff-4a34-a3ef-c2693a63e8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[2023-06-19 11:32:04,995] [INFO] Loading dataset Test_RetailsalesV6...\u001b[0m\n",
      "\u001b[0;32m[2023-06-19 11:32:05,110] [DEBUG] Connecting to database STGIT_prod...\u001b[0m\n",
      "\u001b[0;32m[2023-06-19 11:32:05,361] [DEBUG] STGIT_prod connected successfully !!\u001b[0m\n",
      "\u001b[0;32m[2023-06-19 11:32:06,890] [DEBUG] objects and properties loaded successfully for the dataset ====> 6487fce4-_DgAFr_Vm\u001b[0m\n",
      "\u001b[0;34m[2023-06-19 11:32:07,274] [INFO] smart analytics loaded successfully for the dataset ====> [6487fce4-_DgAFr_Vm]\u001b[0m\n",
      "\u001b[0;34m[2023-06-19 11:32:07,603] [INFO] smart query loaded successfully for the dataset ====> 6487fce4-_DgAFr_Vm\u001b[0m\n",
      "\u001b[0;34m[2023-06-19 11:32:07,950] [INFO] smart column loaded successfully for the dataset ====> 6487fce4-_DgAFr_Vm\u001b[0m\n",
      "\u001b[0;34m[2023-06-19 11:32:08,007] [INFO] Groups loaded successfully for the dataset ====> 6487fce4-_DgAFr_Vm\u001b[0m\n",
      "\u001b[0;34m[2023-06-19 11:32:08,047] [INFO] Roles loaded successfully for the dataset ====> 6487fce4-_DgAFr_Vm\u001b[0m\n",
      "\u001b[0;34m[2023-06-19 11:32:08,422] [INFO] calculated fields loaded successfully for the dataset ====> 6487fce4-_DgAFr_Vm\u001b[0m\n",
      "\u001b[0;34m[2023-06-19 11:32:08,423] [INFO] ***** 6487fce4-_DgAFr_Vm Dataset object created.*****\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "ds = Dataset(\"6487fce4-_DgAFr_Vm\", token=os.getenv(\"CAUTH_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513ee65-6c2d-496e-8abb-41ef016be177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.sqlDf(\"\"\"Select\n",
    "  @RetailSales.order as neworder,\n",
    "  @RetailSales.store_id as id,\n",
    "  @RetailSales.revenue as newcost,\n",
    "  @RetailSales.delivery_date,  \n",
    "  @RetailSales.buyer\n",
    "from\n",
    "  #RetailSales\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68418346-caf1-4eb6-af55-bfd6a766f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "createSmartAnalytics.run(\"Flow_Sales\",\"6448b9f4-CYkYQgs4m\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f1998796-3654-4e4e-8b2e-b3f93d2161a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[2023-11-18 14:07:37,709] [INFO] createSmartAnalytics has been successfully registered. The most recent version available is 5.7 !!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "createSmartAnalytics.register(\"SanityTask\",\"test new tasks\",\"edit\",True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf218d48-3910-443e-8ad8-050812f90a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "createSmartAnalytics.run(\"\",\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72af8563-def5-403b-a873-2e4a7b3c4f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resolveQuery version switched to 4.7'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tsk.SanityTask.resolveQuery.setVersion(4.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba92ffc1-8dec-4b49-9ffa-632f9dc4a3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks loaded  !!\n"
     ]
    }
   ],
   "source": [
    "tsk  = TaskLibrary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e08f51-26dd-4957-a2dd-d329c8722354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flows loaded !!\n"
     ]
    }
   ],
   "source": [
    "flw = FlowLibrary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f5b7d19-7f11-4ad1-a44c-42f38f1939e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flows loaded !!\n"
     ]
    }
   ],
   "source": [
    "flw.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d736779-c03d-4b7f-b514-6e7a065d04aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flows loaded !!\n"
     ]
    }
   ],
   "source": [
    " flw = FlowLibrary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d37c3461-480b-4364-aa41-c2206ed9721f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Version 0.1 for the flow Context_Test has been promoted to O successfully !!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flw.TestingSanity.Context_Test.promote(\"O\",0.1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae44f58b-2758-450f-aa3d-eac92bab4dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flows loaded !!\n"
     ]
    }
   ],
   "source": [
    "flw.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2872fc56-e164-4979-9c77-5c56137ec1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The flow Sanity_Flow has been registered successfully. Latest version available now is 4.9 !!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m Exception ignored in: <function Connection.__del__ at 0x7f683aabd820>\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/heavydb/connection.py\", line 335, in __del__\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m     self.close()\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/heavydb/connection.py\", line 351, in close\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m     self._client.disconnect(self._session)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/heavydb/thrift/Heavy.py\", line 1114, in disconnect\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m     self.send_disconnect(session)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/heavydb/thrift/Heavy.py\", line 1118, in send_disconnect\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m     self._oprot.writeMessageBegin('disconnect', TMessageType.CALL, self._seqid)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/thrift/protocol/TBinaryProtocol.py\", line 54, in writeMessageBegin\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m     self.writeI32(TBinaryProtocol.VERSION_1 | type)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/thrift/protocol/TBinaryProtocol.py\", line 119, in writeI32\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m     self.trans.write(buff)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/thrift/transport/TTransport.py\", line 173, in write\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/thrift/transport/TTransport.py\", line 169, in write\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m     self.__wbuf.write(buf)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=2108)\u001b[0m ValueError: I/O operation on closed file.\n"
     ]
    }
   ],
   "source": [
    "flow.register(libraryName=\"TestingSanity\",flowName=\"Sanity_Flow\",description=\"Flow to test ssanity for git changes    \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0692901-a24c-441c-a280-9d2967eeed24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flows loaded !!\n"
     ]
    }
   ],
   "source": [
    "flw= FlowLibrary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "debcbc91-49f9-45fb-9494-e87bc3394422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Version 4.2 for the flow Sanity_Flow has been promoted to P successfully !!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flw.TestingSanity.Sanity_Flow.promote(\"P\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "66468080-cd54-4b5c-920c-a68e7036683c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flow version for Sanity_Flow changed to 1.3'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flw.TestingSanity.Sanity_Flow.setVersion(1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0b35f23-e0d7-413a-9370-4c66a4d33c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flows loaded !!\n"
     ]
    }
   ],
   "source": [
    "flw.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1ec91c5-fbd6-4946-8da2-07709372a56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipLog is: False\n",
      "\u001b[0;34m[2023-11-30 07:05:53,016] [INFO] [Main-Flow]  Received request from AI Workbench, considering as test run..\u001b[0m\n",
      "\u001b[0;34m[2023-11-30 07:05:53,018] [INFO] Context Actor [25e2102395b445bf8c0a13e413467e55] deployed..\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[31;1m[2023-11-30 07:06:00,936] [CRITICAL] Packegaes are imported  \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;34m[2023-11-30 07:06:00,936] [INFO] os , time , requests imported  \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;34m[2023-11-30 07:06:00,936] [INFO] Dataset is impotted  \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;34m[2023-11-30 07:06:00,937] [INFO] Info lof!!! Data Engine is Connnected  New updated version 2.1 version with try and catch  \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[31;1m[2023-11-30 07:06:00,937] [ERROR] This is not a error Message Just Ignore ---> Dataset is connected \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m Resolved Query ====> Select\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   m_6565c73c_RetailSales.\"m_store_type\" as store,\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   m_6565c73c_RetailSales.\"m_category\" as cat,\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   m_6565c73c_RetailSales.\"m_item_type\" as item_name,\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   m_6565c73c_RetailSales.\"m_item_type\" as item_nameDup\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m from\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   m_6565c73c_RetailSales \n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;34m[2023-11-30 07:06:00,960] [INFO] Query is Resolved \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m \u001b[0;34m[2023-11-30 07:06:01,150] [INFO]  Version is 2.1  \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m \u001b[31;1m[2023-11-30 07:06:01,150] [CRITICAL] Expand and Collapse Rows in pivot tables is a powerful feature that allows users to control the level of detail displayed in their data analysis. By expanding or collapsing rows, analysts can effectively manage large datasets and gain better visibility into the underlying information. The expand and collapse functionality in pivot tables provides valuable control over data visibility, enabling analysts to focus on specific details or obtain a high-level overview of their data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m --- Logging error ---\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m     msg = self.format(record)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m     return fmt.format(record)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/conversight/service/logger.py\", line 43, in format\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m     return formatter.format(record)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m     record.message = record.getMessage()\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m     msg = msg % self.args\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m TypeError: not all arguments converted during string formatting\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m Call stack:\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/ray/workers/default_worker.py\", line 238, in <module>\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/ray/worker.py\", line 451, in main_loop\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m     self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/conversight/flow.py\", line 172, in runWrapperNotebook\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m     output = func(*resolved_params)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m   File \"/tmp/ipykernel_69/3727767676.py\", line 18, in createSmartAnalytics\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m Message: 'log token is by New Version token  ----.'\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m Arguments: ('JWT eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJfZG9jIjp7InVzZXJJZCI6ImM2ZWYyMjJmLWRiZDgtNDBlNy05N2ZiLTQ0NDk3NDBhOTRiZSIsImF0aGVuYUlkIjoiMjZiN2JlNzktOGJlMy00ZjUxLThhNGItNTE3YWFjOGQyNDJlIiwib3JnSWQiOiJjNDY2OTJjNS1lYzVmLTRhOWQtOGQ0ZC1jOTNhZmIyNGRjODYiLCJkZXZpY2VJZCI6IjEyMzQ1NiIsImRldmljZU5hbWUiOiJCcm93c2VyV2ViIiwiaXNUcmlhbFVzZXIiOmZhbHNlLCJpc0ZpcnN0VGltZUxvZ2luIjpmYWxzZSwib3JpZ2luIjoibm90ZWJvb2siLCJjcmVhdGVkQXQiOjE3MDEzMjA0NDk4NzZ9LCJpYXQiOjE3MDEzMjA0MDl9.ihsoPp8tk0CpYSlO6pw2E50SdfhZlwxZBRX4FARSS3w',)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m --- Logging error ---\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m   File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m     msg = self.format(record)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m   File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m     return fmt.format(record)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/conversight/service/logger.py\", line 43, in format\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m     return formatter.format(record)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m   File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m     record.message = record.getMessage()\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m   File \"/opt/conda/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m     msg = msg % self.args\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m TypeError: not all arguments converted during string formatting\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m Call stack:\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/ray/workers/default_worker.py\", line 238, in <module>\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m     ray.worker.global_worker.main_loop()\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/ray/worker.py\", line 451, in main_loop\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m     self.core_worker.run_task_loop()\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m   File \"/opt/conda/lib/python3.9/site-packages/conversight/flow.py\", line 172, in runWrapperNotebook\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m     output = func(*resolved_params)\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m   File \"/tmp/ipykernel_85/842917217.py\", line 28, in omnisciToPandas\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m Message: 'df is --------------------------->'\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m Arguments: (             store       cat    item_name item_nameDup\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m 0      Electronics    Mobile       Tablet       Tablet\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m 1      Electronics    Mobile  Smart Phone  Smart Phone\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m 2      Electronics  Computer      Desktop      Desktop\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m 3        Discounts    Mobile       Tablet       Tablet\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m 4        Discounts    Mobile       Tablet       Tablet\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m ...            ...       ...          ...          ...\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m 15797     Computer    Mobile  Smart Phone  Smart Phone\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m 15798    Discounts    Mobile       Tablet       Tablet\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m 15799  Electronics  Computer       Laptop       Laptop\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m 15800     Computer  Computer      Desktop      Desktop\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m 15801     Computer    Mobile  Smart Phone  Smart Phone\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m \n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=834)\u001b[0m [15802 rows x 4 columns],)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m try is executing \n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;34m[2023-11-30 07:06:01,507] [INFO] SA DF OP:              store       cat    item_name item_nameDup\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m 0      Electronics    Mobile       Tablet       Tablet\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m 1      Electronics    Mobile  Smart Phone  Smart Phone\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m 2      Electronics  Computer      Desktop      Desktop\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m 3        Discounts    Mobile       Tablet       Tablet\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m 4        Discounts    Mobile       Tablet       Tablet\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m ...            ...       ...          ...          ...\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m 15797     Computer    Mobile  Smart Phone  Smart Phone\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m 15798    Discounts    Mobile       Tablet       Tablet\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m 15799  Electronics  Computer       Laptop       Laptop\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m 15800     Computer  Computer      Desktop      Desktop\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m 15801     Computer    Mobile  Smart Phone  Smart Phone\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m [15802 rows x 4 columns]\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:01,512] [DEBUG] Preprocessing log message is !@#$%^&*()_+Q\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:01,623] [DEBUG] Getting connector info....\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:01,704] [DEBUG] Connecting to database STGIT_prod...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:01,993] [DEBUG] STGIT_prod connected successfully !!\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:01,993] [DEBUG] Normalised columns [{store: m_store, cat: m_cat, item_name: m_item_name, item_nameDup: m_item_nameDup}]\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;34m[2023-11-30 07:06:01,994] [INFO] Setting connection details\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:01,994] [DEBUG] Getting connector info....\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:02,086] [DEBUG] Connecting to database STGIT_prod...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:02,373] [DEBUG] STGIT_prod connected successfully !!\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:02,373] [DEBUG] Checking dataset status is active or not...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:02,445] [DEBUG] Dataset is Active...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:02,445] [DEBUG] Does table already exist?\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:03,390] [DEBUG] Creating table m_6565c73c_Flow_SalesTest...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:03,413] [DEBUG] Table m_6565c73c_Flow_SalesTest created successfully !!\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:03,413] [DEBUG] Loading table m_6565c73c_Flow_SalesTest with data...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:03,413] [DEBUG] Load as Arrow format set to ====> [False] and original dataFrame type is ====>  [<class pandas.core.frame.DataFrame>] \u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:03,413] [DEBUG] Loading Pandas Dataframe...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:03,596] [DEBUG] Data loaded successfully !!\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:03,596] [DEBUG] Creating metadata for the table [Flow_SalesTest] ...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:03,596] [DEBUG] Checking dataset status is active or not...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:03,643] [DEBUG] Dataset is Active...\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:10,760] [DEBUG] The columns has been created successfully\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;32m[2023-11-30 07:06:10,760] [DEBUG] Metadata created successfully !!\u001b[0m\n",
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[33;20m[2023-11-30 07:06:10,814] [WARNING] Dataset [655616ec-DoFu92IIm] is not active, current status is: Active and refreshStatus: Active]\u001b[0m\n",
      "\u001b[0;34m[2023-11-30 07:06:21,598] [INFO] [Main-Flow]  Flow response: [{status: success, message : Smart analytics created and sme published successfully !!}]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'status': 'success',\n",
       "  'message ': 'Smart analytics created and sme published successfully !!'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(runWrapperNotebook pid=803)\u001b[0m \u001b[0;34m[2023-11-30 07:06:21,597] [INFO] SME data published successfully !!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "flw.TestingSanity.Sanity_v1.run(datasetIdEffectiveness= \"65140d2a-bpGojtZIi\",Query=  \"\"\"Select\n",
    "  @RetailSales.store_type as store,\n",
    "  @RetailSales.category as cat,\n",
    "  @RetailSales.item_type as item_name,\n",
    "  @RetailSales.item_type as item_nameDup\n",
    "from\n",
    "  #RetailSales\"\"\" , objectName= \"Flow_SalesTest\", isArrow = False,isOverWrite = False,isPublish= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad13d3-9c2f-460f-910b-f5323347394a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2c4610f-7956-489c-8a30-e9bdc807117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks loaded  !!\n"
     ]
    }
   ],
   "source": [
    "tsk= TaskLibrary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "181ae565-15a2-4037-8657-db6002ba13d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flows loaded !!\n"
     ]
    }
   ],
   "source": [
    "flw = FlowLibrary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e46bd575-eb31-4b60-8d83-22b76caae089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flow version for Sanity_Flow changed to 4.7'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flw.TestingSanity.Sanity_Flow.pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07dd4f64-fbd6-4336-bfa7-edd0f31b33a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flow version for Sanity_Flow changed to 0.8'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flw.TestingSanity.Sanity_Flow.setVersion(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab4a904-e786-4e0f-a9b2-04f55f4533cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "flw.TestingSanity.Sanity_Flow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31cc6423-8157-4ed7-816a-d16b4a929dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><head><style>\n",
       "            #table_css {\n",
       "            font-family: Arial, Helvetica, sans-serif;\n",
       "            border-collapse: collapse;\n",
       "            width: 99.8%;\n",
       "            table-layout: auto;\n",
       "            font-size: 14px\n",
       "            }\n",
       "            #table_css td, #table_css th {\n",
       "            border: 1px solid #ddd;\n",
       "            padding: 8px;\n",
       "            text-align:center;\n",
       "            width:auto;\n",
       "            }\n",
       "            #table_css tr {background-color: #f2f2f2;}\n",
       "            #table_css tr:hover {background-color: #ddd;}\n",
       "            #table_css th {\n",
       "            padding-top: 12px;\n",
       "            padding-bottom: 12px;\n",
       "            text-align: center;\n",
       "            background-color: #04AA6D;\n",
       "            color: white;\n",
       "            }\n",
       "            .left-align {text-align:left !important;}\n",
       "    </style></head><body><table id='table_css'><tr> <th>#</th> <th>Version</th> <th>Description</th> <th>Type</th> <th style='width: 62px;'>Sub Type</th> <th>Level</th> <th>Inputs</th> <th>Outputs</th> <th style='width: 110px;'>Registered ORG</th> <th>Slug</th> </tr> <tr> <td>1 </td> <td> 0.1 </td> <td class='left-align'> Task color changes  </td> <td> generic </td>  <td> Function </td> <td> U </td> <td> objectName: <class 'str'>, dataSetId: <class 'str'>, dataFrame: <class 'pandas.core.frame.DataFrame'>, isArrow: <class 'bool'>, isOverwrite: <class 'bool'> </td> <td> <class 'dict'> </td> <td> STGIT </td> <td> 5e903d3d-8128-46f9-8004-1849faa2fbc5 </td></tr><tr> <td>2 </td> <td> 0.2 </td> <td class='left-align'> Task color changes  </td> <td> generic </td>  <td> Function </td> <td> U </td> <td> objectName: <class 'str'>, dataSetId: <class 'str'>, dataFrame: <class 'pandas.core.frame.DataFrame'>, isArrow: <class 'bool'>, isOverwrite: <class 'bool'> </td> <td> <class 'dict'> </td> <td> STGIT </td> <td> 5e903d3d-8128-46f9-8004-1849faa2fbc5 </td></tr><tr> <td>3 </td> <td> 0.3 </td> <td class='left-align'> Task color changes  </td> <td> generic </td>  <td> Function </td> <td> U </td> <td> objectName: <class 'str'>, dataSetId: <class 'str'>, dataFrame: <class 'pandas.core.frame.DataFrame'>, isArrow: <class 'bool'>, isOverwrite: <class 'bool'> </td> <td> <class 'dict'> </td> <td> STGIT </td> <td> 5e903d3d-8128-46f9-8004-1849faa2fbc5 </td></tr><tr> <td>4 </td> <td> 0.4 </td> <td class='left-align'> Task color changes  </td> <td> generic </td>  <td> Function </td> <td> U </td> <td> objectName: <class 'str'>, dataSetId: <class 'str'>, dataFrame: <class 'pandas.core.frame.DataFrame'>, isArrow: <class 'bool'>, isOverwrite: <class 'bool'> </td> <td> <class 'dict'> </td> <td> STGIT </td> <td> 5e903d3d-8128-46f9-8004-1849faa2fbc5 </td></tr> </table></body></html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsk.ColortaskSanity.createSmartAnalytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2567c55-79f9-4757-8000-ba32708d4951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
